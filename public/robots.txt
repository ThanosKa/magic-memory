# robots.txt for Magic Memory

# Allow all crawlers
User-agent: *
Allow: /

# Disallow authenticated/user-specific pages
Disallow: /api/
Disallow: /restore/
Disallow: /_next/
Disallow: /.well-known/

# Sitemap reference
# TODO: set production sitemap URL
Sitemap: http://localhost:3000/sitemap.xml

# Crawl-delay for specific bots (if needed)
User-agent: GPTBot
Disallow: /

User-agent: ChatGPT-User
Disallow: /
